{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ec91a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "65d860ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KKMeans():\n",
    "    def __init__(self, n_clusters=8, init=\"random\", n_init=1,\n",
    "                 max_iter=300, tol=None, verbose=0,\n",
    "                 random_state=None, algorithm=\"lloyd\", kernel=\"linear\", **kwds):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.init = init\n",
    "        self.n_init = n_init\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "        self.random_state = check_random_state(random_state)\n",
    "        self.algorithm = algorithm\n",
    "        self.kernel = kernel\n",
    "        self.kwds = kwds\n",
    "        self.labels = None\n",
    "        self.device = self.init_torch()\n",
    "        return\n",
    "    \n",
    "    def init_torch(self):\n",
    "        # TODO allow user to set device.\n",
    "        if not torch.cuda.is_available():\n",
    "            print(\"Warning! Code is running on Cpu using Numpy.\",\n",
    "                  \"On larger datasets this may be too slow.\")\n",
    "            return torch.device(\"cpu\")\n",
    "        return torch.device(\"cuda:0\")\n",
    "        \n",
    "    \n",
    "    def p_kernel_wrapper(self, x, y=None):\n",
    "        return pairwise_kernels(x, y, metric=self.kernel, n_jobs=-1, **self.kwds)\n",
    "    \n",
    "    def fit(self, data):\n",
    "        self._check_data(data)\n",
    "        \n",
    "        if self.algorithm == \"lloyd\":\n",
    "            #self._lloyd(data)\n",
    "            self._lloyd_pytorch(data)\n",
    "    def _check_data(self, data):\n",
    "        return\n",
    "    \n",
    "    def _lloyd(self, data):\n",
    "        kernel_matrix = self.p_kernel_wrapper(data)\n",
    "        self._init(data, kernel_matrix)\n",
    "        inertia = 0\n",
    "        for _ in range(self.max_iter):\n",
    "            distances = np.tile(np.diag(kernel_matrix), (self.n_clusters, 1)).T\n",
    "            self._lloyd_iter(kernel_matrix, distances)\n",
    "            labels_new = np.argmin(distances, axis=1)\n",
    "            inertia_new = np.amin(distances, axis=1).sum()\n",
    "            if all(labels_new == self.labels) or abs(inertia - inertia_new) < self.tol:\n",
    "                if self.verbose:\n",
    "                    print(\"Converged at iteration:\", _ + 1,\n",
    "                          \"Inertia:\", inertia_new)\n",
    "                break                \n",
    "            if self.verbose:\n",
    "                print(\"Iteration:\", _ + 1,\n",
    "                      \"Inertia:\", inertia_new)\n",
    "            self.labels = labels_new\n",
    "            inertia = inertia_new            \n",
    "    \n",
    "    def _lloyd_iter(self, kernel_matrix, distances):\n",
    "        for cluster in range(self.n_clusters):\n",
    "            mask = (self.labels == cluster)\n",
    "            n_cluster_elements = sum(mask) \n",
    "            if n_cluster_elements == 0:\n",
    "                if self.verbose:\n",
    "                    print(\"Empty Cluster encountered,\",  \n",
    "                          \"assigned random element to cluster.\")\n",
    "                self.labels[self.random_state.randint(len(self.labels))] = cluster\n",
    "                n_cluster_elements = 1      \n",
    "            # (SUM K(a,b) for a,b in Cluster) / |cluster|**2 \n",
    "            inner_term = kernel_matrix[mask][:, mask].sum() / (n_cluster_elements ** 2)\n",
    "            # array that contains for each datapoint x: 2 * (SUM K(x,b) for b in Cluster) / |Cluster|\n",
    "            element_term = 2 * kernel_matrix[:, mask].sum(axis = 1) / n_cluster_elements\n",
    "            distances[:, cluster] += inner_term\n",
    "            distances[:, cluster] -= element_term\n",
    "            \n",
    "    def _lloyd_pytorch(self, data):\n",
    "        kernel_matrix = torch.tensor(self.p_kernel_wrapper(data), device = self.device)\n",
    "        self._init(data, kernel_matrix)\n",
    "        self.labels = torch.tensor(self.labels, device = self.device) # TODO refactor!!!\n",
    "        inertia = 0\n",
    "        for _ in range(self.max_iter):\n",
    "            distances = torch.tile(torch.diag(kernel_matrix), (self.n_clusters, 1)).T\n",
    "            self._lloyd_iter_pytorch(kernel_matrix, distances)\n",
    "            \n",
    "            labels_new = torch.argmin(distances, dim = 1)\n",
    "            inertia_new = torch.sum(torch.amin(distances, dim  = 1))\n",
    "            if all(labels_new == self.labels) or abs(inertia - inertia_new) < self.tol:\n",
    "                if self.verbose:\n",
    "                    print(\"Converged at iteration:\", _ + 1,\n",
    "                          \"Inertia:\", inertia_new)\n",
    "                break                \n",
    "            if self.verbose:\n",
    "                print(\"Iteration:\", _ + 1,\n",
    "                      \"Inertia:\", inertia_new)\n",
    "            self.labels = labels_new\n",
    "            inertia = inertia_new    \n",
    "                \n",
    "        \n",
    "    \n",
    "    def _lloyd_iter_pytorch(self, kernel_matrix, distances):\n",
    "        for cluster in range(self.n_clusters):\n",
    "            mask = (self.labels == cluster)\n",
    "            n_cluster_elements = sum(mask)\n",
    "            if n_cluster_elements == 0:\n",
    "                if self.verbose:\n",
    "                    print(\"Empty Cluster encountered,\",  \n",
    "                          \"assigned random element to cluster.\")\n",
    "                self.labels[self.random_state.randint(len(self.labels))] = cluster\n",
    "                n_cluster_elements = 1    \n",
    "            inner_term = torch.div(torch.sum(kernel_matrix[mask][:, mask]), n_cluster_elements ** 2)\n",
    "            element_term = torch.div(2 * torch.sum(kernel_matrix[:, mask], dim = 1), n_cluster_elements)\n",
    "            distances[:, cluster].add_(inner_term) #inplace adding\n",
    "            distances[:, cluster].add_(-element_term) #inplace adding\n",
    "    \n",
    "    def _init(self, data, kernel_matrix):\n",
    "        if isinstance(self.init, (list, tuple, np.ndarray)):\n",
    "            self._check_centroids() # TODO \n",
    "            self._assign_to_centroids(self.init, data)\n",
    "            return\n",
    "        \n",
    "        elif self.init == \"random\":\n",
    "            centroids = data[self.random_state.randint(0, len(data), self.n_clusters)]\n",
    "            self._assign_to_centroids(centroids, data)\n",
    "            return\n",
    "        \n",
    "        elif self.init == \"truerandom\":\n",
    "            self.labels = self.random_state.randint(0, self.n_clusters, len(data))\n",
    "            return\n",
    "        \n",
    "        elif self.init == \"kmeans++\":\n",
    "            self._kmeanspp(data, kernel_matrix)\n",
    "            return \n",
    "        \n",
    "        raise Exception(\"Unknown initialisation method\")\n",
    "    \n",
    "    def _check_centroids(self):\n",
    "        if len(self.init) != self.n_clusters:\n",
    "            raise Exception(\"The number of given centroids should match n_clusters\") # TODO\n",
    "        return\n",
    "\n",
    "    def _assign_to_centroids(self, centroids, data):\n",
    "        data_centr_kernel = self.p_kernel_wrapper(data, centroids)\n",
    "        centr_distances = np.zeros((len(data), self.n_clusters))\n",
    "        for cluster in range(self.n_clusters):\n",
    "            centr_distances[:, cluster] = (-2 * data_centr_kernel[:, cluster]\n",
    "                + self.p_kernel_wrapper([centroids[cluster]]))\n",
    "        self.labels = np.argmin(centr_distances, axis = 1)\n",
    "        return\n",
    "\n",
    "    \n",
    "    def _kmeanspp(self, data, kernel_matrix):   \n",
    "        centroids = np.zeros((self.n_clusters, len(data[0])))\n",
    "        centr_distances = np.tile(np.diag(kernel_matrix), (self.n_clusters, 1)).T   \n",
    "        for cluster in range(self.n_clusters):\n",
    "            if cluster == 0:\n",
    "                #random first center\n",
    "                index = self.random_state.randint(len(data))\n",
    "            else:\n",
    "                max_dist_each = np.amin(centr_distances[:, :cluster + 1], axis = 1)\n",
    "                max_dist_each[max_dist_each < 0] = 0\n",
    "                probs = max_dist_each/max_dist_each.sum()\n",
    "                index = self.random_state.choice(len(data), size = 1, p = probs)\n",
    "            centroids[cluster] = data[index]\n",
    "            cluster_term = self.p_kernel_wrapper([centroids[cluster]])\n",
    "            data_term = self.p_kernel_wrapper(data, [centroids[cluster]])\n",
    "            centr_distances[:, cluster] += (-2 * data_term + cluster_term).reshape(len(data),)    \n",
    "        self.labels = np.argmin(centr_distances, axis = 1)\n",
    "                \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c73239ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs, make_circles\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dd5a5469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(data, labels):\n",
    "    if len(data[0]) > 3:\n",
    "        raise Exception(\"Dimensionality is too high for visualization\")\n",
    "    elif len(data[0]) == 1:\n",
    "        plt.scatter(data, [0 for x in range(len(data))], c = labels)\n",
    "    elif len(data[0]) == 2:\n",
    "        plt.scatter(data[:,0], data[:,1], c = labels)\n",
    "    elif len(data[0]) == 3:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(projection = \"3d\")\n",
    "        ax.scatter(data[:,0], data[:,1], data[:,2], c = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0a9bf64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, labels, centers = make_blobs(10000, centers = 10, return_centers = True, random_state = 0, n_features = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bd4b2d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "kkm = KKMeans(n_clusters = 10, verbose = True, init = \"random\", kernel = \"linear\", random_state = 0, tol = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ea7d8f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 Inertia: 42353.95845739827\n",
      "Iteration: 2 Inertia: 26513.383210256234\n",
      "Iteration: 3 Inertia: 25321.15671169784\n",
      "Iteration: 4 Inertia: 24624.188850550097\n",
      "Iteration: 5 Inertia: 23917.19853285682\n",
      "Iteration: 6 Inertia: 23049.312410560375\n",
      "Iteration: 7 Inertia: 22060.256215511414\n",
      "Iteration: 8 Inertia: 20767.879265434483\n",
      "Iteration: 9 Inertia: 19238.35477228299\n",
      "Iteration: 10 Inertia: 18241.86309666612\n",
      "Iteration: 11 Inertia: 17960.10040337619\n",
      "Iteration: 12 Inertia: 17925.34373443215\n",
      "Iteration: 13 Inertia: 17922.630014837192\n",
      "Iteration: 14 Inertia: 17922.26535766422\n",
      "Converged at iteration: 15 Inertia: 17922.22442016487\n"
     ]
    }
   ],
   "source": [
    "kkm.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b8389c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
